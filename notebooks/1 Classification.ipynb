{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "from pathlib import Path\n",
    "import scipy.stats as st\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from src.sugnet.pipeline import FeatureExtractor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = GroupShuffleSplit(n_splits=3, test_size=0.2)\n",
    "CHANCE_CV = GroupShuffleSplit(n_splits=100, test_size=0.2)\n",
    "n_permutations = 100\n",
    "output_path = Path('data/classification_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data\n",
    "DATA = pd.read_csv('docs/plb_hyp_data_long.csv', index_col=0)\n",
    "\n",
    "# clean unwanted observations\n",
    "DATA = DATA.query('description == \"hypnosis\"')\n",
    "DATA = DATA.query('condition.str.contains(\"experience\")')\n",
    "\n",
    "\n",
    "DATA = DATA.query('bids_id <= 50')\n",
    "DATA['bids_id'] = DATA['bids_id'].apply(lambda x: str(x).rjust(2, '0'))\n",
    "\n",
    "#Xy\n",
    "X = DATA[['bids_id','procedure']].values\n",
    "y = DATA['hypnosis_depth'].apply(lambda x: 0 if x <= 5 else 1).values\n",
    "groups = DATA['bids_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5333333333333333,\n",
       " 0.023570226039551605,\n",
       " BootstrapResult(confidence_interval=ConfidenceInterval(low=0.5, high=0.5333333333333333), standard_error=0.01340064250602664))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. PIPELINE\n",
    "pipe = Pipeline([\n",
    "    ('extract', FeatureExtractor()),\n",
    "    ('zerovar', VarianceThreshold(threshold=0.0)),\n",
    "    ('scale', StandardScaler()),\n",
    "    # ('pca', PCA(n_components=30)),\n",
    "    ('select', SelectFromModel(SVC(kernel=\"linear\", max_iter=100000), max_features=13)),\n",
    "    ('clf', SVC(kernel=\"linear\", max_iter=100000, probability=True)),\n",
    "])\n",
    "# DEBUG: pipe.fit(X, y).score(X, y)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipe, X, y, groups=groups, cv=CV, scoring='accuracy')\n",
    "scores.mean(), scores.std(), st.bootstrap(scores.reshape(1, -1), np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=GroupShuffleSplit(n_splits=3, random_state=None, test_size=0.2,\n",
       "         train_size=None),\n",
       "             estimator=Pipeline(steps=[('extract', FeatureExtractor()),\n",
       "                                       ('zerovar', VarianceThreshold()),\n",
       "                                       ('scale', StandardScaler()),\n",
       "                                       ('select',\n",
       "                                        SelectFromModel(estimator=SVC(kernel='linear',\n",
       "                                                                      max_iter=100000),\n",
       "                                                        max_features=13)),\n",
       "                                       ('clf',\n",
       "                                        SVC(kernel='linear', max_iter=100000,\n",
       "                                            probability=True))]),\n",
       "             param_grid=[{'extract__frequency_band': ['theta', 'alpha', 'beta',\n",
       "                                                      'gamma', 'all'],\n",
       "                          'extract__kind': ['correlation source',\n",
       "                                            'power source', 'power sensor',\n",
       "                                            'plv source']},\n",
       "                         {'extract__kind': ['correlation sensor']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = [{\n",
    "    'extract__kind': ['correlation source', 'power source', 'power sensor', 'plv source'],\n",
    "    'extract__frequency_band': ['theta', 'alpha', 'beta', 'gamma', 'all'],\n",
    "    \n",
    "}, {\n",
    "    'extract__kind': ['correlation sensor'],\n",
    "}]\n",
    "\n",
    "grid = GridSearchCV(pipe, grid_params, cv=CV, scoring='accuracy', verbose=1)\n",
    "grid.fit(X, y, groups=groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare grid results to plot\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "grid_results['label'] = grid_results['params'].apply(lambda p: ' '.join(list(p.values())[0].values()))\n",
    "\n",
    "split_cols = [c for c in grid_results.columns if 'split' in c]\n",
    "\n",
    "grid_results['test_score'] = grid_results[split_cols].apply(lambda x: list(x), axis=1)\n",
    "grid_results.drop(columns=split_cols, inplace=True)\n",
    "grid_results = grid_results.explode('test_score')\n",
    "\n",
    "\n",
    "def fit_chance(model_name=None):\n",
    "    \"\"\"Utility function to simulate emperical chance level.\"\"\"\n",
    "    \n",
    "    chance_model = DummyClassifier(strategy='most_frequent')\n",
    "    chance_scores = cross_val_score(chance_model, X, y, groups=groups, cv=CHANCE_CV, scoring='accuracy')\n",
    "    return chance_scores\n",
    "\n",
    "chance_scores = {}\n",
    "for model_name in grid_results['label'].unique():\n",
    "    model_chance_scores = fit_chance(model_name)\n",
    "    chance_scores[f'{model_name}'] = model_chance_scores.tolist()\n",
    "    \n",
    "chance_scores = pd.DataFrame(chance_scores).melt(var_name='label', value_name='test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance against chance level\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "order = grid_results.groupby('label')['test_score'].mean().sort_values(ascending=False).index.values\n",
    "\n",
    "# plot chance\n",
    "sns.pointplot(data=chance_scores, ax=ax,\n",
    "              x='test_score', y='label',\n",
    "              order=order,\n",
    "              color='gray',\n",
    "              capsize=0.03,\n",
    "              join=False,\n",
    "              orient='h', label='chance')\n",
    "\n",
    "# plot observed\n",
    "sns.pointplot(data=grid_results, x='test_score', y='label',\n",
    "              orient='h',\n",
    "              order=order,\n",
    "              ax=ax,\n",
    "              scale=3,\n",
    "              cmap='viridis',\n",
    "              capsize=0.03,\n",
    "              join=False,\n",
    "              color='blue',\n",
    "              markers='D')\n",
    "\n",
    "# sns.stripplot(data=grid_results, x='test_score', y='label',\n",
    "#               orient='h',\n",
    "#               order=order,\n",
    "#               ax=ax,\n",
    "#               cmap='viridis',\n",
    "#               color='blue',\n",
    "#               marker='D')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pipe.set_params(**grid.best_params_)\n",
    "X_t = pipe[:-2].fit_transform(X, y)\n",
    "\n",
    "permutation_importance(pipe[-2:], X_t, y, n_repeats=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('otka')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5940ee23a8ed7b2e3c21178d81a306e47a8b6a3c2b3d99c2f75b67b005e8c5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
