{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### imports\n",
    "import xarray as xr\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "from autoreject import AutoReject\n",
    "from autoreject import get_rejection_threshold\n",
    "\n",
    "#### open documnets and retreive essential information\n",
    "# find hypnosis-introduced-as-hypnosis trials\n",
    "\n",
    "# open long formatted behavioral data \n",
    "data = pd.read_excel('docs/data_with_psds.xlsx', header=1, index_col='Unnamed: 0')\n",
    "\n",
    "# get the index of the condition where hypnosis introduced as real hypnosis\n",
    "truehypnosis_ind = [(i+1) - 4*int(i/4)\n",
    "                    for i in range(len(data))\n",
    "                    if (data.iloc[i]['description_type'] == 'hypnosis' and data.iloc[i]['trial_type'] == True)]\n",
    "truehypnosis_series = pd.Series(truehypnosis_ind,index=data.index.drop_duplicates(), name='true_hyp_ind')\n",
    "\n",
    "# remove two participants with software crash\n",
    "truehypnosis_series = truehypnosis_series.iloc[:50]\n",
    "\n",
    "# open ids map to match the behavioral with bids ids\n",
    "ids_map = pd.read_excel('docs/ids_map.xlsx', header=1, index_col='behavioral_id').bids_id\n",
    "\n",
    "# remove the two participants with software crash in ids map\n",
    "ids_map = ids_map.loc[:2132614].drop_duplicates()\n",
    "\n",
    "# change index type and merge to series\n",
    "ids_map.index = ids_map.index.astype('int64')\n",
    "realHypInd = pd.concat([ids_map,truehypnosis_series],axis=1)\n",
    "\n",
    "# set bids ids as index and get the experience trial index based on the subject id\n",
    "realHypInd.set_index('bids_id', inplace=True)\n",
    "\n",
    "# delete junks\n",
    "del truehypnosis_ind; del truehypnosis_series; del ids_map\n",
    "\n",
    "#### utilitty functions\n",
    "# real hypnosis index finder\n",
    "def task_ind_finder(sub):\n",
    "    exp_ind = realHypInd.loc[int(sub), 'true_hyp_ind']\n",
    "    return exp_ind\n",
    "\n",
    "# cut noisy parts\n",
    "def cut_noisy(raw, task, language):\n",
    "    \"\"\"\n",
    "    First step of preprocessing in my pipeline!\n",
    "    it's important to get rid of noisy parts in baseline and experinece segments: informed from the audio files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        eeg raw data\n",
    "    task : str\n",
    "        can be experience1, etc or baseline1 or baseline2\n",
    "    language : str\n",
    "        language of the experiment ['eng' or 'hun']\n",
    "    \"\"\"\n",
    "    # validate task and language name\n",
    "    import re\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    if not re.fullmatch('(baseline[12])|(experience[1-4])',task):\n",
    "        raise Exception('Invalid task!')\n",
    "    \n",
    "    tasklang = task + language\n",
    "\n",
    "    # helper named tuple to make the code more readable\n",
    "    Interval = namedtuple('Interval', ['tmin', 'tmax'])\n",
    "\n",
    "    cut_intervals = {\n",
    "        '(experience[1-4](eng|hun))|baseline1hun': Interval(tmin=20, tmax=320),       \n",
    "        'baseline1eng': Interval(tmin=25, tmax=325),       \n",
    "        'baseline2(eng|hun)': Interval(tmin=30, tmax=330),       \n",
    "        }\n",
    "    interval = [value for key,value in cut_intervals.items() if re.fullmatch(key, tasklang)][0]\n",
    "\n",
    "    raw.crop(tmin=interval.tmin, tmax=interval.tmax)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset from data of two tasks of two persons\n",
    "bids_root = Path('data/Main-study')\n",
    "subjects = ['01', '02']\n",
    "tasks = ['baseline1', 'experience']\n",
    "allSubjectsTasks = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    # timpoints and initialize\n",
    "    timepoints = 30001 # change this if resampling data\n",
    "    allSubjects = np.empty((1,61, timepoints))\n",
    "\n",
    "    # Open data of a specific task for all subjects one by one, reshape and append them\n",
    "    for sub in subjects:\n",
    "        # find hypnosis-as-hypnosis trial index (only for experience)\n",
    "        if task == 'experience':\n",
    "            ind = task_ind_finder(sub); task = task + str(ind)\n",
    "        bids_path = mne_bids.BIDSPath(subject=sub, session='01', task=task, root=bids_root)\n",
    "        raw = mne_bids.read_raw_bids(bids_path, verbose=False)\n",
    "        # Cut noisy parts only for experience and baseline task\n",
    "        if task[:-1] in ['baseline', 'experience']:\n",
    "            raw = cut_noisy(raw, task,'hun')\n",
    "        \n",
    "        # raw.resample(256)\n",
    "        # Get eeg data as np.array and add subject dimension\n",
    "        # TODO check if getting data this way can change data's precision\n",
    "        oneSubject = np.expand_dims(raw.get_data(),0)\n",
    "\n",
    "        allSubjects = np.append(allSubjects, oneSubject, axis=0)\n",
    "\n",
    "    # remove empty array\n",
    "    allSubjects = np.delete(allSubjects, 0, axis=0)\n",
    "\n",
    "    # mega data\n",
    "    allSubjectsTasks[task] = allSubjects\n",
    "    \n",
    "## open dataset with mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating xarray from the dict\n",
    "baseline = allSubjectsTasks['baseline1']\n",
    "experience = allSubjectsTasks['experience1']\n",
    "subjects = subjects\n",
    "ch_names = raw.ch_names\n",
    "_, times = raw.get_data(return_times=True)\n",
    "\n",
    "dataset = xr.Dataset(\n",
    "    {\n",
    "        \"baseline\": ([\"subject\", \"electrodes\", \"time\"], baseline),\n",
    "        \"experience\": ([\"subject\", \"electrodes\", \"time\"], experience)\n",
    "    },\n",
    "    coords={\n",
    "        \"subjects\": ([\"subject\"], subjects),\n",
    "        \"ch_names\": ([\"electrodes\"], ch_names),\n",
    "        \"times\": ([\"time\"], times)\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "# save and check the size (if it was ok we will use all data)\n",
    "comp = dict(zlib=True, complevel=9)\n",
    "encoding = {var: comp for var in dataset.data_vars}\n",
    "dataset.to_netcdf('data/dataset.nc', engine=\"h5netcdf\", encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d539ee110e3d7f72862ae1acc5ad197a6467511f7b01c5e88c321aa8b0a828d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
