{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTKA1 post analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "############### Constants ###############\n",
    "# define brain patches and frequency boundries\n",
    "## channels name\n",
    "epochs = mne.read_epochs('data/clean_data/sub-01_ses-01_task-baseline1_proc-clean_epo.fif')\n",
    "ch_names = epochs.ch_names.copy()  # make sure to copy the list because it is mutable in place\n",
    "[ch_names.remove(i) for i in ['M1', 'M2', 'EOG1', 'EOG2', 'ECG']]\n",
    "all_channels = epochs.ch_names\n",
    "\n",
    "# name of electrode groups\n",
    "ba_patches = {'LF': ['Fp1', 'F3', 'F7', 'AF3', 'F1', 'F5'],\n",
    " 'LC': ['C3', 'T7', 'FC1', 'FC3', 'FC5', 'C1', 'C5', 'FT7'],\n",
    " 'LP': ['P3', 'P7', 'CP1', 'CP3', 'CP5', 'TP7', 'P1', 'P5'],\n",
    " 'LO': ['O1', 'PO3'],\n",
    " 'RF': ['Fp2', 'F4', 'F8', 'AF4', 'F2', 'F6',],\n",
    " 'RC': ['C4', 'T8', 'FC2', 'FC4', 'FC6', 'C2', 'C6', 'FT8'],\n",
    " 'RP': ['P4', 'P8', 'CP2', 'CP4', 'CP6', 'TP8', 'P2', 'P6'],\n",
    " 'RO': ['O2', 'PO4'],\n",
    " 'FZ': ['Fpz', 'Fz'],\n",
    " 'OZ': ['POz', 'Oz', 'Iz'],\n",
    "}\n",
    "\n",
    "# index of electrode groups\n",
    "ba_patches_ind = {}\n",
    "for k,v in ba_patches.items():\n",
    "    temp = [all_channels.index(i) for i in v]\n",
    "    ba_patches_ind[k] = temp\n",
    "\n",
    "# frequency indces\n",
    "freq = dict(delta=(0, 23),\n",
    "            theta=(24, 55),\n",
    "            alpha=(56, 95),\n",
    "            beta=(96, 232),\n",
    "            gamma=(233, 330))\n",
    "\n",
    "############ Helper Functions ############\n",
    "def calculate_psd(epochs,\n",
    "                  eeg_dir='data/clean_data/',\n",
    "                  save_path='data/psds_dict.pkl',\n",
    "                  save=False,\n",
    "                  pick_channels=False,\n",
    "                  ch_indices=None):\n",
    "    psds_dict = {}\n",
    "    for path in sorted(Path(eeg_dir).glob('sub-*.fif')):\n",
    "        subject, task = re.search('sub-(.*)_ses-01_task-(.*)_proc-clean_epo.*', path.stem).groups()\n",
    "        if task == 'baseline2' or 'induction' in task:\n",
    "            continue\n",
    "        print('>>>>>> get psds for subject: ', subject, ' task: ', task, ' <<<<<<')\n",
    "        epochs = mne.read_epochs(path)\n",
    "        data = np.hstack(epochs.get_data())\n",
    "        if pick_channels:\n",
    "            data = data[ch_indices]\n",
    "        psds,freqs = psd_array_welch(data,\n",
    "                                     sfreq=1000,\n",
    "                                     fmin=1,\n",
    "                                     fmax=42,\n",
    "                                     n_fft=8000,\n",
    "                                     verbose=0,\n",
    "                                     average=None\n",
    "                                     )\n",
    "        psds_dict[subject+'_'+task] = psds\n",
    "\n",
    "    psds_dict['freqs'] = freqs\n",
    "    if save:\n",
    "        with open(save_path, 'wb') as handle:\n",
    "            pickle.dump(psds_dict, handle)\n",
    "    return psds_dict\n",
    "\n",
    "def aggregate_psds(psds_dict, ba_patches_ind, freq):\n",
    "    \"\"\"Aggregate PSDs across channels and frequency bands.\"\"\"\n",
    "    # create a dataframe from aggreagated data, power in picovolts\n",
    "    psds_agg = {}\n",
    "    for k1, v1 in psds_dict.items():\n",
    "        for k2, v2 in ba_patches_ind.items():\n",
    "            for k3, v3 in freq.items():\n",
    "                psds_agg[k1+'-'+k2+'_'+k3] = v1[v2].mean(0)[v3[0]:v3[1]].mean(0) * 10000 ** 3 #picovolts\n",
    "    return psds_agg\n",
    "\n",
    "def create_classification_df(psds_agg,\n",
    "                             bh_path='data/behavioral_data/archived/behavioral_data.csv',\n",
    "                             save_path='data/classification_datasets/power_sensor_3rd.csv',\n",
    "                             save=False):\n",
    "    df = pd.DataFrame(psds_agg.items(), columns=['index', 'values']).set_index('index')\n",
    "    df[['session', 'power']] = df.index.to_series().apply(lambda x:x.split('-')).apply(pd.Series)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.pivot(index='session', columns='power', values='values')\n",
    "\n",
    "    # merge behavioral data with power data\n",
    "    # open behavioral data\n",
    "    bh = pd.read_csv(bh_path)\n",
    "    bh = bh.iloc[:208]\n",
    "\n",
    "    # merge with power data\n",
    "    df[['bids_id', 'condition']] = df.index.to_series().apply(lambda x:x.split('_')).apply(pd.Series)\n",
    "    df['session'] = df['condition'].apply(lambda x:x[-1])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # change session and bids_id type at once to be the same type as the behavioral data\n",
    "    df = df.astype({'session': 'int64'})\n",
    "    df = pd.merge(bh, df, how='right', on=['session', 'bids_id'], right_index=False)\n",
    "    df.insert(1, 'condition', df.pop('condition'))\n",
    "    df = df.sort_values(by=['bids_id', 'session', 'condition']).reset_index(drop=True)\n",
    "\n",
    "    if save:\n",
    "        df.to_csv(save_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate unaggreated psds\n",
    "eeg_dir = '/Volumes/Extreme_SSD/PhD/OTKA_study1/clean_data/'\n",
    "save_path = 'docs/psds_unaggregared_OZ-FZ_14112024.pkl'\n",
    "ch_indices = ba_patches_ind['OZ'] + ba_patches_ind['FZ']\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'rb') as handle:\n",
    "        psds_dict = pickle.load(handle)\n",
    "    freqs = psds_dict['freqs']\n",
    "    psds_dict.pop('freqs')\n",
    "else:\n",
    "    psds_dict = calculate_psd(epochs, eeg_dir, save_path=save_path, save=True,\n",
    "                              pick_channels=True, ch_indices=ch_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-transformation of the power values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_z_trans = {}\n",
    "bands = ['theta', 'alpha', 'gamma']\n",
    "for k in psds_dict.keys():\n",
    "    print('>>>>>>>>>', k)\n",
    "    if 'baseline' in k:\n",
    "        base = psds_dict[k]\n",
    "        base_mean = base.mean(2)\n",
    "        base_std = base.std(2)\n",
    "        continue\n",
    "    activity = psds_dict[k]\n",
    "    activity_z = (activity - base_mean[:, :, np.newaxis]) / base_std[:, :, np.newaxis]\n",
    "    activity_z = activity_z.mean(2)\n",
    "    sub, task = k.split('_')\n",
    "    for band in bands:\n",
    "        # OZ_alpha_aper_experience1\n",
    "        psds_z_trans[sub+'_'+'OZ_'+band+'_'+task+'_Z-trans'] = activity_z[:3, freq[band][0]:freq[band][1]].mean(1).mean(0)\n",
    "        psds_z_trans[sub+'_'+'FZ_'+band+'_'+task+'_Z-trans'] = activity_z[3:, freq[band][0]:freq[band][1]].mean(1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = pd.DataFrame(data=psds_z_trans.values(), index=psds_z_trans.keys(), columns=['values'])\n",
    "df_z['bids_id'] = df_z.index.to_series().apply(lambda x:np.float64(x.split('_')[0]))\n",
    "df_z['cols'] = df_z.index.to_series().apply(lambda x:x.split('_')[1:]).apply(lambda x:'_'.join(x))\n",
    "df_z = df_z.pivot(index='bids_id', columns='cols', values='values')\n",
    "# add nine rows of NaNs to the firs of the dataframe to match the behavioral data\n",
    "df_z = pd.concat([pd.DataFrame(np.nan, index=np.arange(9), columns=df_z.columns), df_z])\n",
    "df_z['bids_id'] = df_z.index\n",
    "df_z.iloc[:9, -1] = np.nan  # set the first 9 bids_ids to NaN\n",
    "df_z.reset_index(drop=True, inplace=True)\n",
    "# df_z.to_csv('data/z_trans_power_sensor_OZ-FZ.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another way of z-transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_data = pd.read_csv('data/classification_datasets/power_sensor.csv', index_col=0)\n",
    "bands = ['theta', 'alpha', 'gamma']\n",
    "cols = [i for i in power_data.columns for j in bands if j in i and ('FZ' in i or 'OZ' in i) and 'decibel' not in i]\n",
    "cols = ['bids_id', 'condition'] + cols\n",
    "\n",
    "# baseline\n",
    "baseline = power_data[cols].query(\"condition.str.contains('baseline1')\").reset_index(drop=True).drop('condition', axis=1)\n",
    "# repeat each row 2 times\n",
    "baseline = pd.concat([baseline]*4, ignore_index=True).sort_values('bids_id').reset_index(drop=True)\n",
    "baseline = baseline.melt(id_vars=['bids_id'], var_name='sensor_base', value_name='power_base')\n",
    "\n",
    "\n",
    "# expeirience\n",
    "experience = power_data.query(\"condition.str.contains('experience')\")\n",
    "experience = experience[cols].dropna().reset_index(drop=True)\n",
    "experience = experience.melt(id_vars=['bids_id', 'condition'], var_name='sensor_exp', value_name='power_exp')\n",
    "\n",
    "# join\n",
    "experience = experience.join(baseline, lsuffix='_exp', rsuffix='_base').drop('bids_id_base', axis=1).rename(columns={'bids_id_exp': 'bids_id'})\n",
    "experience['bids_id'] = experience['bids_id'].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "# baseline correct and z transform the power\n",
    "experience['baseline_corrected'] = experience.apply(lambda r: r['power_exp'] - r['power_base'], axis=1)\n",
    "experience['baseline_corrected'] = experience['baseline_corrected'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_1 = psd1['01-experience1'].mean(axis=0)\n",
    "psd_z = (psd_1[3] - np.mean(psd_1[3])) / np.std(psd_1[3])\n",
    "psd_zc = (psd_1[3] - baseline_1[3].mean()) / np.std(baseline_1[3])\n",
    "psd_subtracted = psd_1[3] - baseline_1[3].mean()\n",
    "\n",
    "plt.plot(freqs, psd_z, label='z-transfomed')\n",
    "plt.plot(freqs, psd_zc, label='z-transfomed with baseline')\n",
    "plt.plot(freqs, psd_subtracted * 10**12, label='subtracted baseline')\n",
    "plt.plot(freqs, psd_2, label='decible conversion')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGModalNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
